# ReAct(Reason Act)Agent

Agent：ReAct结构和SOP结构

> ***[ReAct: Synergizing Reasoning and Acting in Language Models](http://arxiv.org/abs/2210.03629)*** 发表于Iclr at 2023，

![React](pics/t3/React.png)

React背景和意义：复杂逻辑推理的任务进行处理和行动规划

## ReAct的处理方法：

- **推理**：模型首先对问题进行推理，生成一个执行计划。
- **行动**：然后，模型根据这个执行计划执行具体的行动步骤。
- 这种方法通过将推理和行动紧密结合，使得模型能够更有效地处理复杂任务

### 架构：

​	ReAct模型由两个主要部分组成：推理器（Reasoner）和执行器（Actor）。

- **推理器**：负责生成执行计划，通常是一个序列到序列的模型，训练数据包括输入问题和对应的正确执行计划，loss是生成的执行计划与真实执行计划之间的差异。
- **执行器**：根据执行计划执行具体的操作，如查询知识库、生成问题的答案，目标确保执行器能够根据推理器生成的执行计划正确地执行操作。

### 训练策略：

传统的RF包括：

- 观察

- 动作

- 内容

- 策略

  搜索空间较大缺乏llm的常识指导

Prompt设计：

用llm，相当于引入人类思考辅助决策下一步Act

调用wikipediaapi，有三种act：

- search[entity]：返回前五句话ifnull则返回相似的top-5 entities
- lookup[string]：在wiki页面匹配字符串
- finish[answer]：

​		模型通过监督学习和强化学习相结合的方式进行训练。监督学习提供了一个基础，使得推理器和执行器能够学习基本的任务知识。而强化学习则进一步优化执行器的行为，使其能够适应不同的任务和环境。

结果和结论：ReAct和ChainofThought结合起来效果最好

## 教程的笔记：

1. **构造大模型**：使用InternLM2模型（基于Decoder-Only的通用对话模型）作为Agent模型。
   - 创建`BaseModel`类，定义基本方法如`chat`和`load_model`。
   - 创建`InternLM2`类，继承自`BaseModel`，实现具体的加载和聊天方法
2. **构造工具**：在tools.py文件中构建Tools类，假如Google搜索等功能。
   - 添加工具描述信息，以便在构造system_prompt时让模型知道可调用的工具和参数。
   - 实现具体的工具功能，如Google搜索，需要申请token于https://serper.dev/dashboard。
3. **构造Agent**：在Agent.py文件中构建一个React范式的Agent类，实现text_completion方法。
   - 构建`system_prompt`，提供给大模型一些系统的提示信息。
   - 解析用户提问，选择调用的工具和参数。
   - 调用选择的工具，并将结果与用户提问整合
4. **运行Agent**：使用InternLM2-chat-7B模型或InternLM2-20b-chat模型运行Agent。
   - 实现了React范式的Agent，包括构建系统提示、解析插件调用、调用插件和文本完成的方法。

参考：[github.com/datawhalechina/tiny-universe](https://github.com/datawhalechina/tiny-universe/blob/main/content/TinyAgent/readme.md)